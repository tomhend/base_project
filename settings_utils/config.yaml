train_dataset_cfg:
  name: prosab_ct
  kwargs:
    index_file_path: .\input_files\nifti_input_train.csv
train_dataloader_cfg:
  batch_size: 6
  shuffle: True
  num_workers: 8
  drop_last: False

val_dataset_cfg:
  name: prosab_ct
  kwargs:
    index_file_path:.\input_files\nifti_input_val.csv
val_dataloader_cfg:
  batch_size: 6
  shuffle: False
  num_workers: 8
  drop_last: False

trainer_cfg:
  name: base_trainer

model_cfg:
  name: convnet_3d
  kwargs:
    n_classes: 1
    input_size: [1, 20, 128, 128]
    out_channels_list: [8, 16, 32]
    kernel_sizes: [7, 3, 3]
    strides: [1, 1, 1]
    maxpool_sizes: [3, 2, 2]
    maxpool_strides: [3, 2, 2]
    dropout_chances: [null, null, null]

loss_cfg:
  name: bce_logits
  kwargs:
    pos_weight: 2.6 #209/79

optimizer_cfg:
  name: adam
  kwargs:
    lr: 0.00001

session_cfg:
  epochs: 5
  metrics: ['loss_train_step', 'acc_train_epoch', 'acc_val_epoch'] #training and validation loss alway logged on epoch
# selection metric: loss_val_epoch # NOTE: only epoch based metrics are supported for selection
# goal: minimize

log_cfg:
  wandb_init:
    project: prosab_hydrocephalus
    job_type: train
