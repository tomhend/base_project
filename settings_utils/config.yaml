train_dataset_cfg:
  name: prosab_ct
  kwargs:
    index_file_path: C:\Users\thendriks\code\git_repositories\base_project\input_files\nifti_input_train_csv.csv
train_dataloader_cfg:
  batch_size: 10
  shuffle: True
  num_workers: 4
  drop_last: False

val_dataset_cfg:
  name: prosab_ct
  kwargs:
    index_file_path: C:\Users\thendriks\code\git_repositories\base_project\input_files\nifti_input_val_csv.csv
val_dataloader_cfg:
  batch_size: 5
  shuffle: False
  num_workers: 4
  drop_last: False

trainer_cfg:
  name: base_trainer

model_cfg:
  name: medical_net50
  kwargs:
    pretrain: True
    weights_path: C:\Users\thendriks\code\git_repositories\base_project\models\weights\resnet_50_23dataset.pth
    input_shape: [32, 256, 256]
    n_classes: 1

loss_cfg:
  name: bce_logits

optimizer_cfg:
  name: adam
  kwargs:
    lr: 0.001

session_cfg:
  epochs: 10
  metrics: ['loss_train_step', 'acc_train_epoch', 'acc_val_epoch'] #training and validation loss alway logged on epoch
# selection metric: loss_val_epoch # NOTE: only epoch based metrics are supported for selection
# goal: minimize

log_cfg:
  wandb_init:
    project: base_project
    job_type: prototype
