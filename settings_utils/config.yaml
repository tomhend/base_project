train_dataset_cfg:
  name: prosab_ct
  kwargs:
<<<<<<< HEAD:config.yaml
    index_file_path: C:\Users\thendriks\code\git_repositories\base_project\input_files\nifti_input_train_csv.csv
=======
    size: 10
    image_size: [3,256,256]
    classes: 1000
>>>>>>> main:settings_utils/config.yaml
train_dataloader_cfg:
  batch_size: 10
  shuffle: True
  num_workers: 4
  drop_last: False

val_dataset_cfg:
  name: prosab_ct
  kwargs:
<<<<<<< HEAD:config.yaml
    index_file_path: C:\Users\thendriks\code\git_repositories\base_project\input_files\nifti_input_val_csv.csv
=======
    size: 2
    image_size: [3,256,256]
    classes: 1000
>>>>>>> main:settings_utils/config.yaml
val_dataloader_cfg:
  batch_size: 5
  shuffle: False
  num_workers: 4
  drop_last: False

trainer_cfg:
  name: base_trainer

model_cfg:
  name: medical_net50
  kwargs:
    pretrain: True
    weights_path: C:\Users\thendriks\code\git_repositories\base_project\models\weights\resnet_50_23dataset.pth
    input_shape: [32, 256, 256]
    n_classes: 1

loss_cfg:
  name: bce_logits

optimizer_cfg:
  name: adam
  kwargs:
    lr: 0.001

session_cfg:
  epochs: 10
<<<<<<< HEAD:config.yaml
=======
  metrics: ['loss_train_step', 'acc_train_epoch', 'acc_val_epoch'] #training and validation loss alway logged on epoch
# selection metric: loss_val_epoch # NOTE: only epoch based metrics are supported for selection
# goal: minimize
>>>>>>> main:settings_utils/config.yaml

log_cfg:
  wandb_init:
    project: base_project
<<<<<<< HEAD:config.yaml
    job_type: prototype
  log_fns: ['loss_train_step', 'loss_train_epoch', 'loss_val_epoch', 'bi_acc_val_epoch']
=======
    job_type: prototype
>>>>>>> main:settings_utils/config.yaml
